<!DOCTYPE html>
<html>
    <head>
        <title>TIKA : TikaEval</title>
        <link rel="stylesheet" href="styles/site.css" type="text/css" />
        <META http-equiv="Content-Type" content="text/html; charset=UTF-8">
    </head>

    <body class="theme-default aui-theme-default">
        <div id="page">
            <div id="main" class="aui-page-panel">
                <div id="main-header">
                    <div id="breadcrumb-section">
                        <ol id="breadcrumbs">
                            <li class="first">
                                <span><a href="index.html">TIKA</a></span>
                            </li>
                                                </ol>
                    </div>
                    <h1 id="title-heading" class="pagetitle">
                                                <span id="title-text">
                            TIKA : TikaEval
                        </span>
                    </h1>
                </div>

                <div id="content" class="view">
                    <div class="page-metadata">
                        
        
    
    
        
    
        
        
            Created by <span class='author'> ASF Infrabot</span>, last modified by <span class='editor'> Tim Allison</span> on окт 26, 2022
                        </div>
                    <div id="main-content" class="wiki-content group">
                    <h1 id="TikaEval-Overviewofthe&#39;tika-eval-app&#39;Module">Overview of the 'tika-eval-app' Module</h1><p>This page offers a first draft of the documentation for the tika-eval-app module, which was initially added to Tika 1.15.</p><p>The module is intended to offer insight from the output of a single extraction tool or to enable some comparisons between tools. This module is designed to be used to help with Tika, but it could be used to evaluate other tools as well.</p><p>As part of Tika's periodic regression testing, we run this module against ~3 million files (for committers/PMC interested in running the regression testing on our regression vm, see <a class="external-link" href="https://wiki.apache.org/tika/TikaEvalOnVM" rel="nofollow">TikaEvalOnVM</a>). However, it will not scale to 100s of millions of files as it is currently designed. Patches are welcomed!</p><h1 id="TikaEval-Background">Background</h1><p>There are many tools for extracting text from various file formats, and even within a single tool there are usually countless parameters that can be tweaked. The goal of 'tika-eval' is to allow developers to quickly compare the output of:</p><ol><li>Two different tools</li><li>Two versions of the same tool (&quot;Should we upgrade? Or are there problems with the newer version?&quot;)</li><li>Two runs with the same tool but with different settings (&quot;Does increasing the DPI for OCR improve extraction? Let's try two runs, one with 200 DPI and one with 300&quot;)</li><li>Different tools against a gold standard</li></ol><p>In addition to this &quot;comparison mode&quot;, there is also plenty of information one can get from looking at a profile of a single run.</p><p>Some basic metrics for both the &quot;comparison&quot; and &quot;profiling&quot; mode might include:</p><ul><li>Exceptions – how many and of what category? Are these regular catchable exceptions, evil OOMs or permahangs?</li><li>Metadata – how many metadata values did we extract?</li><li>Embedded files/attachments – how many embedded files were found</li><li>Mime detection – how many of what types of files do we have? Where do we see discrepancies between tools?</li><li>Content – is the content extracted by tool A better than that extracted by tool B? On which files is there a big difference in extracted content?</li></ul><p>The tika-eval module was initially developed for text only. For those interested in evaluating structure/style components (e.g. &lt;title/&gt; or &lt;b/&gt; elements), see <a href="TikaEvalAndStructuralComponents_109454085.html">TikaEvalAndStructuralComponents</a>.</p><h1 id="TikaEval-QuickStartUsage">Quick Start Usage</h1><p><strong>NOTE:</strong> tika-eval will not overwrite the contents of the database you specify in Profile or Compare mode. Add <code>-drop</code> to the commandline to drop tables if you are reusing the database.</p><p>The following assumes that you are using the default in-memory H2 database. To connect tika-eval to your own db via jdbc see <a href="TikaEvalJdbc_109454088.html">TikaEvalJdbc</a>.</p><h2 id="TikaEval-SingleOutputfromOneTool(Profile)">Single Output from One Tool (Profile)</h2><p><strong>NOTE:</strong> assume the original input files are in a directory named <code>input_docs</code> and that the text extracts are written to the <code>extracts</code> directory, with each extract file having the same sub-directory path and same file name with '.json' or '.txt' appended to it.</p><ol><li>Create a directory of extract files that mirrors your input directory. These files may be UTF-8 text files with '.txt' appended to the original file's name or they may be the RecursiveParserWrapper's '.json' representation: <code>java -jar tika-app-X.Y.jar -J -t -i input_docs -o extracts</code></li><li>Profile the directory of extracts and create a local H2 database:<br/><code>java -jar tika-eval-X.Y.jar Profile -extracts extracts -db profiledb</code></li><li>Write reports from the database: <br class="atl-forced-newline"/><code>java -jar tika-eval-X.Y.jar Report -db profiledb</code></li></ol><p>You'll have a directory of .xlsx reports under the &quot;reports&quot; directory.  <strong>Note:</strong> if you don't need the full tika-eval-app, you can get many of these statistics at parse time via the TikaEvalMetadataFilter (see: <a href="ModifyingContentWithHandlersAndMetadataFilters_217385627.html">ModifyingContentWithHandlersAndMetadataFilters</a>).</p><h2 id="TikaEval-ComparingOutputfromTwoTools/Settings(Compare)">Comparing Output from Two Tools/Settings (Compare)</h2><p><strong>NOTE:</strong> assume the original input files are in a directory named <code>input_docs</code> and that the text extracts from tool A are written to the <code>extractsA</code> directory and the extracts from tool B are written to <code>extractsB</code>.</p><ol><li>Create two directories of extract files that mirror your input directory. These files may be UTF-8 text files with '.txt' appended to the original file's name or they may be the RecursiveParserWrapper's '.json' representation.</li><li>Compare the extract directory A with extract directory B and write results to a local H2 database:<br/><code>java -jar tika-eval-X.Y.jar Compare -extractsA extractsA -extractsB extractsB -db comparisondb</code></li><li>Write reports from the database:<br/><code>java -jar tika-eval-X.Y.jar Report -db comparisondb</code></li></ol><p>You'll have a directory of .xlsx reports under the &quot;reports&quot; directory.</p><h2 id="TikaEval-InvestigatingtheDatabase">Investigating the Database</h2><ol><li>Launch the H2 localhost server:<br/><code>java -jar tika-eval-X.Y.jar StartDB</code> – this calls <code>java -cp ... org.h2.tools.Console -web</code></li><li>Navigate a browser to <code><a class="external-link" href="http://localhost:8082" rel="nofollow">http://localhost:8082</a></code> and enter the jdbc connector code followed by the <strong>full path</strong> to your db file:<br/><code>jdbc:h2:/C:/users/someone/mystuff/tika-eval/comparisondb</code></li></ol><p>If your reaction is: &quot;You call this a database?!&quot;, please open tickets and contribute to improving the structure.</p><p>See <a href="TikaEvalDbDesign_109454086.html">TikaEvalDbDesign</a> for more information on the underlying structure of the database.</p><h1 id="TikaEval-Moredetailedusage">More detailed usage</h1><h2 id="TikaEval-EvaluatingSuccessviaCommonWords">Evaluating Success via Common Words</h2><p>In the absence of ground truth, it is often helpful to count the number of common words that were extracted (see <a href="TikaEvalMetrics_109454089.html">TikaEvalMetrics</a> for a discussion of this).</p><p>&quot;Common words&quot; are specified per language in the &quot;resources/commonwords&quot; directory. <br/>Each file is named for the language code, e.g. 'en', and each file is a UTF-8 text file with one word per line.</p><p>The token processor runs language id against content and then selects the appropriate set of common words for its counts. If there is no common words file for a language, then it backs off to the default list, which is currently hardcoded to 'en'.</p><p>Make sure that your common words have gone through the same analysis chain as specified by the Common Words analyzer in '<a class="external-link" href="https://github.com/apache/tika/blob/master/tika-eval/src/main/resources/lucene-analyzers.json" rel="nofollow">lucene-analyzers.json</a>'!</p><h2 id="TikaEval-ReadingExtracts">Reading Extracts</h2><h3 id="TikaEval-alterExtract">alterExtract</h3><p>Let's say you want to compare the output of Tika to another tool that extracts text. You happen to have a directory of .json files for Tika and a directory of UTF-8 .txt files from the other tool.</p><ol><li>If the other tool extracts embedded content, you'd want to concatenate all the content within Tika's .json file for a fair comparison:<br/><code>java -jar tika-eval-X.Y.jar Compare -extractsA tika_1_14 -extractsB tika_1_15 -db comparisondb -alterExtract concatenate_content</code></li><li>If the other tool does not extract embedded content, you'd only want to look at the first metadata object (representing the container file) in the .json file:<br/><code>java -jar tika-eval-X.Y.jar Compare -extractsA tika_1_14 -extractsB tika_1_15 -db comparisondb -alterExtract first_only</code></li></ol><h3 id="TikaEval-Min/MaxExtractSize">Min/Max Extract Size</h3><p>You may find that some extracts are too big to fit in memory, in which case use <code>-maxExtractSize &lt;maxBytes&gt;</code>, or you may want to focus only on extracts that are greater than a minimum length: <code>-minExtractSize &lt;minBytes&gt;</code>.</p><h2 id="TikaEval-Reports">Reports</h2><p>The module tika-eval comes with a list of reports. However, you might want to generate your own. Each report is specified by SQL and a few other configurations in an xml file. See <code>comparison-reports.xml</code> and <code>profile-reports.xml</code> to get a sense of the syntax.</p><p>To specify your own reports on the commandline, use <code>-rf</code> (report file):<br/><code>java -jar tika-eval-X.Y.jar Report -db comparisondb -rf myreports.xml</code></p><p>If you'd like to write the reports to a root directory other than 'reports', specify that with <code>-rd</code> (report directory):<br/><code>java -jar tika-eval-X.Y.jar Report -db comparisondb -rd myreportdir</code></p><p>Again, see <a href="TikaEvalDbDesign_109454086.html">TikaEvalDbDesign</a> for more information on the underlying structure of the database.</p>
                    </div>

                                        
                 
                </div>             </div> 
            <div id="footer" role="contentinfo">
                <section class="footer-body">
                    <p>Document generated by Confluence on мая 02, 2023 15:13</p>
                    <div id="footer-logo"><a href="https://www.atlassian.com/">Atlassian</a></div>
                </section>
            </div>
        </div>     </body>
</html>
