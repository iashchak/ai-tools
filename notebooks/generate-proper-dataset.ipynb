{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Install dependencies\n",
    "We install pytorch with built-in CUDA support. If you don't have CUDA, you can install pytorch without CUDA support. You can find more information [here](https://pytorch.org/get-started/locally/).\n",
    "Also we install transformers, pandas, mwparserfromhell, nltk, accelerate and nvidia-ml-py3.\n",
    "We use mwparserfromhell to parse the raw text of the Wikipedia articles, nltk for tokenization, accelerate for multi-GPU training and nvidia-ml-py3 for GPU monitoring."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages)\n",
      "ERROR: Directory '//' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (4.28.1)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: mwparserfromhell in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (0.6.4)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: accelerate in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: nvidia-ml-py3 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (7.352.0)\n",
      "Requirement already satisfied: datasets in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from transformers) (0.13.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.4.0 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from accelerate) (2.0.0+cu117)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: xxhash in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: responses<0.19 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: multiprocess in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from torch>=1.4.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from torch>=1.4.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from torch>=1.4.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from jinja2->torch>=1.4.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages (from sympy->torch>=1.4.0->accelerate) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\programdata\\anaconda3\\envs\\ai-tools\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https: // download.pytorch.org/whl/cu117\n",
    "!pip install transformers pandas mwparserfromhell nltk accelerate nvidia-ml-py3 datasets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T21:37:57.315075Z",
     "end_time": "2023-04-20T21:38:00.646677Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download data from Wikipedia\n",
    "We download each article about some specific category from Wikipedia. We use the category \"Science fiction films\" as an example. You can change the category to any other category you want. We also remove the references and external links sections from the articles and wiki markup and save the result to a CSV file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from typing import List, Tuple, Dict\n",
    "import mwparserfromhell\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set the category you want to download\n",
    "csv_filename = \"../data/articles.csv\"\n",
    "articles_category = 'Science_fiction_films'\n",
    "\n",
    "# Get the list of subcategories and articles\n",
    "def get_category_members(category: str, member_type: str) -> List[str]:\n",
    "    base_url = 'https://en.wikipedia.org/w/api.php'\n",
    "    params = {\n",
    "        'action': 'query',\n",
    "        'list': 'categorymembers',\n",
    "        'cmtitle': category,\n",
    "        'cmtype': member_type,\n",
    "        'format': 'json',\n",
    "        'cmlimit': 500\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    data = response.json()\n",
    "    for item in data['query']['categorymembers']:\n",
    "        yield item['title']\n",
    "\n",
    "# Get the raw text of the articles\n",
    "def get_article_texts(articles: List[str]) -> Dict[str, str]:\n",
    "    base_url = 'https://en.wikipedia.org/w/api.php'\n",
    "    params = {\n",
    "        'action': 'query',\n",
    "        'prop': 'revisions',\n",
    "        'rvprop': 'content',\n",
    "        'format': 'json',\n",
    "        'titles': '|'.join(articles)\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    data = response.json()\n",
    "    for page in data['query']['pages'].values():\n",
    "        yield page['revisions'][0]['*']\n",
    "\n",
    "# Download the articles by chunks of 50 articles\n",
    "def download_articles(category: str):\n",
    "    # Get the list of subcategories and articles\n",
    "    subcategories = list(get_category_members(f'Category:{category}', 'subcat'))\n",
    "    all_articles = []\n",
    "\n",
    "    # Download the articles from the subcategories\n",
    "    for subcategory in tqdm(subcategories, desc=\"Downloading subcategories\"):\n",
    "        articles = list(get_category_members(subcategory, 'page'))\n",
    "        all_articles.extend(articles)\n",
    "\n",
    "    # Download the articles by chunks of 50 articles\n",
    "    for i in tqdm(range(0, len(all_articles), 50), desc=\"Downloading articles\"):\n",
    "        batch = all_articles[i:i + 50]\n",
    "        texts = dict(zip(batch, get_article_texts(batch)))\n",
    "        for title, raw_text in texts.items():\n",
    "            wikicode = mwparserfromhell.parse(raw_text)\n",
    "            # Remove the references and external links sections\n",
    "            for section in wikicode.get_sections(levels=[2]):\n",
    "                if section.filter_headings()[0].title.strip().lower() in [\"references\", \"external links\"]:\n",
    "                    wikicode.remove(section)\n",
    "            text = wikicode.strip_code().strip()\n",
    "            yield {'title': title, 'raw_text': raw_text, 'text': text}\n",
    "\n",
    "# Download the articles and save them to a CSV file\n",
    "if not os.path.exists(csv_filename):\n",
    "    articles_df = pd.DataFrame(download_articles(articles_category))\n",
    "    articles_df = articles_df.dropna(subset=['text'])\n",
    "    articles_df.to_csv(csv_filename, index=False)\n",
    "else:\n",
    "    # If the CSV file already exists, we just load it\n",
    "    articles_df = pd.read_csv(csv_filename)\n",
    "    articles_df.to_csv(csv_filename, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T21:38:00.646677Z",
     "end_time": "2023-04-20T21:38:02.856516Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate question-answer pairs\n",
    "We use T5 to generate question-answer pairs from the Wikipedia articles. We use the T5-small model and the T5 tokenizer.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "Generating questions and answers:   0%|          | 0/1366 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8804ccba76ce435eadd1365381ad5af3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1594 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Bird began writing its screenplay in earnest the next year; he attempted to distinguish the script from the breadth of superhero-related content released since the first film, focusing on the family dynamics rather than the superhero genre.\n",
      "Answer: Bird began writing its screenplay in earnest the next year; he attempted to distinguish the script from the breadth of superhero-related content released since the first film, focusing on the family dynamics rather than the superhero genre.\n",
      "\n",
      "\n",
      "Question: Highlights: Avatar (2009) and Alita: Battle Angel (2019) were both films to be shot using 3D technology. The film received strong critical acclaim and became the highest-grossing film of all time in the United States and Canada, becoming the highest-grossing film of all time in the United States and Canada, surpassing Titanic. The film earned a fair $108 million at the worldwide box office.\n",
      "Answer: Avatar (2009) and Alita: Battle Angel (2019) were both films to be shot using 3D technology. Cameron had shown interest in making Avatar (2009) and Alita: Battle Angel (2019) as early as June 2005 with both films to be shot using 3D technology. He wanted to make Alita: Battle Angel first, followed by Avatar but switched the order in February 2006. Although receiving mixed reviews, the film earned a fair $108 million at the worldwide box office.\n",
      "\n",
      "\n",
      "Question: What is the name of James Cameron's unrealized projects?\n",
      "Answer: List of people who descended to Challenger Deep List of vegans\n",
      "\n",
      "\n",
      "Question: Collection of all USATODAY.com coverage of John Carpenter., including articles, videos, photos, and quotes.\n",
      "Answer: Discography Albums Year Title Distributor 1974 Dark Star Bryanston Distributing Company 1976 Assault on Precinct 13, Big Trouble in Little China, Prince of Darkness, and Ghosts of Mars\n",
      "\n",
      "\n",
      "Question: How did Kerry Conran feel about Sky Captain and the World of Tomorrow?\n",
      "Answer: he did acknowledge that his film had indeed become influential\n",
      "\n",
      "\n",
      "Question: Michael Crichton's third novel, Eaters of the Dead, is a science fiction novel based on a fictional privateer who attempts to raid a Spanish galleon. Crichton was the creator and executive producer of the television drama ER based on his 1974 pilot script 24 Hours. Crichton also published The Lost World in 1995 as the sequel to Jurassic Park.\n",
      "Answer: Several novels that were in various states of completion upon Crichton's death have since been published. The first, Pirate Latitudes, was found as a manuscript on one of his computers after his death. Crichton had completed the outline for and was roughly a third of the way through a novel titled Micro, a historical novel set during the Bone Wars\n",
      "\n",
      "\n",
      "Question: Tim Burton and Timur Bekmambetov, director of Wanted, showed interest in producing a feature-length adaptation of the film.\n",
      "Answer: Burton co-produced Abraham Lincoln: Vampire Hunter with actors Johnny Depp and Helena Bonham Carter\n",
      "\n",
      "\n",
      "Question: Lucas worked as a creative consultant on the Star Wars sequel trilogy's first film, The Force Awakens. Lucas met with J. J. Abrams before the latter began writing the script to the sequel trilogy's final film, The Rise of Skywalker, which was released in 2019. Lucas met with J. J. Abrams before the latter began writing the script to the sequel trilogy's final film, The Rise of Skywalker.\n",
      "Answer: Lucas met with J. J. Abrams before the latter began writing the script to the sequel trilogy's final film, The Rise of Skywalker. Lucas met with J. J. Abrams before the latter began writing the script to the sequel trilogy's final film, The Rise of Skywalker.\n",
      "\n",
      "\n",
      "Question: What is the name of the bibliography of Georges Méliès bibliography?\n",
      "Answer: Georges Méliès bibliography La Maison de la Magie Robert-Houdin Segundo de Chomón\n",
      "\n",
      "\n",
      "Question: Honda's funeral reunited Akira Kurosawa and Toshiro Mifune, an actor who had starred in both Honda's and Kurosawa's early films.\n",
      "Answer: Honda's funeral reunited Akira Kurosawa and Toshiro Mifune, an actor who had starred in both Honda and Kurosawa's early films.\n",
      "\n",
      "\n",
      "Question: What is the name of the director of Tobe Hooper - Collaborators?\n",
      "Answer: Chukwudi Iwuji Daniela Melchior Flula Borg Gregg Henry Kevin Bacon Lloyd Kaufman Michael Rooker Michael Rosenbaum Mikaela Hoover Nathan Fillion Rob Zombie\n",
      "\n",
      "\n",
      "Question: What is the name of the movie that Leonard starred in?\n",
      "Answer: Brett Leonard - See also Cinema of the Soviet Union\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 8.74 GiB (GPU 0; 6.00 GiB total capacity; 466.23 MiB already allocated; 2.99 GiB free; 1.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 49\u001B[0m\n\u001B[0;32m     43\u001B[0m rows \u001B[38;5;241m=\u001B[39m tqdm(\n\u001B[0;32m     44\u001B[0m     articles_df\u001B[38;5;241m.\u001B[39miterrows(),\n\u001B[0;32m     45\u001B[0m     desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerating questions and answers\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     46\u001B[0m     total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(articles_df)\n\u001B[0;32m     47\u001B[0m )\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, row \u001B[38;5;129;01min\u001B[39;00m rows:\n\u001B[1;32m---> 49\u001B[0m     created_question_answers \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_and_evaluate_questions_and_answers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m     question_answers_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([question_answers_df, created_question_answers])\n\u001B[0;32m     52\u001B[0m \u001B[38;5;66;03m# Сохраните обновленный датафрейм (например, в файл CSV)\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[1], line 33\u001B[0m, in \u001B[0;36mgenerate_and_evaluate_questions_and_answers\u001B[1;34m(row)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m section\u001B[38;5;241m.\u001B[39mfilter_headings()[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mtitle\u001B[38;5;241m.\u001B[39mstrip()\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreferences\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexternal links\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m---> 33\u001B[0m question \u001B[38;5;241m=\u001B[39m \u001B[43mmake_query_to_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mAsk the large question about following: \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtitle\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m - \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43msection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrip_code\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrip\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     34\u001B[0m answer \u001B[38;5;241m=\u001B[39m make_query_to_model(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAnswer the question and provide some details. Question: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquestion\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Context: Article about \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrow[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtitle\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m - \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msection\u001B[38;5;241m.\u001B[39mstrip_code()\u001B[38;5;241m.\u001B[39mstrip()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mlen\u001B[39m(question) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m50\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\u001B[38;5;28mlen\u001B[39m(answer) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m50\u001B[39m):\n",
      "Cell \u001B[1;32mIn[1], line 24\u001B[0m, in \u001B[0;36mmake_query_to_model\u001B[1;34m(query)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmake_query_to_model\u001B[39m(query) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[0;32m     22\u001B[0m     input_ids \u001B[38;5;241m=\u001B[39m tokenizer(query, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39minput_ids\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 24\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_beams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.7\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tokenizer\u001B[38;5;241m.\u001B[39mdecode(outputs[\u001B[38;5;241m0\u001B[39m], skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ai-tools\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ai-tools\\lib\\site-packages\\transformers\\generation\\utils.py:1286\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, streamer, **kwargs)\u001B[0m\n\u001B[0;32m   1278\u001B[0m         logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[0;32m   1279\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA decoder-only architecture is being used, but right-padding was detected! For correct \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1280\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgeneration results, please set `padding_side=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m` when initializing the tokenizer.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1281\u001B[0m         )\n\u001B[0;32m   1283\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder_outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m model_kwargs:\n\u001B[0;32m   1284\u001B[0m     \u001B[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001B[39;00m\n\u001B[0;32m   1285\u001B[0m     \u001B[38;5;66;03m# and added to `model_kwargs`\u001B[39;00m\n\u001B[1;32m-> 1286\u001B[0m     model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_encoder_decoder_kwargs_for_generation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1287\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_input_name\u001B[49m\n\u001B[0;32m   1288\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1290\u001B[0m \u001B[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001B[39;00m\n\u001B[0;32m   1291\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder:\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ai-tools\\lib\\site-packages\\transformers\\generation\\utils.py:638\u001B[0m, in \u001B[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001B[1;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001B[0m\n\u001B[0;32m    636\u001B[0m encoder_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreturn_dict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    637\u001B[0m encoder_kwargs[model_input_name] \u001B[38;5;241m=\u001B[39m inputs_tensor\n\u001B[1;32m--> 638\u001B[0m model_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder_outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m]: ModelOutput \u001B[38;5;241m=\u001B[39m \u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mencoder_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    640\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_kwargs\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ai-tools\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ai-tools\\lib\\site-packages\\accelerate\\hooks.py:165\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    163\u001B[0m         output \u001B[38;5;241m=\u001B[39m old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 165\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mold_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ai-tools\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1086\u001B[0m, in \u001B[0;36mT5Stack.forward\u001B[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1073\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m checkpoint(\n\u001B[0;32m   1074\u001B[0m         create_custom_forward(layer_module),\n\u001B[0;32m   1075\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1083\u001B[0m         \u001B[38;5;28;01mNone\u001B[39;00m,  \u001B[38;5;66;03m# past_key_value is always None with gradient checkpointing\u001B[39;00m\n\u001B[0;32m   1084\u001B[0m     )\n\u001B[0;32m   1085\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1086\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1087\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1088\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1089\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1090\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1091\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1092\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_decoder_position_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_decoder_position_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1093\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1094\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1095\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1096\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1097\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1098\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;66;03m# layer_outputs is a tuple with:\u001B[39;00m\n\u001B[0;32m   1101\u001B[0m \u001B[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001B[39;00m\n\u001B[0;32m   1102\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ai-tools\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ai-tools\\lib\\site-packages\\accelerate\\hooks.py:165\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    163\u001B[0m         output \u001B[38;5;241m=\u001B[39m old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 165\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mold_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ai-tools\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:693\u001B[0m, in \u001B[0;36mT5Block.forward\u001B[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001B[0m\n\u001B[0;32m    690\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    691\u001B[0m     self_attn_past_key_value, cross_attn_past_key_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 693\u001B[0m self_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    694\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    695\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    696\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    697\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    698\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    699\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    700\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    701\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m hidden_states, present_key_value_state \u001B[38;5;241m=\u001B[39m self_attention_outputs[:\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m    703\u001B[0m attention_outputs \u001B[38;5;241m=\u001B[39m self_attention_outputs[\u001B[38;5;241m2\u001B[39m:]  \u001B[38;5;66;03m# Keep self-attention outputs and relative position weights\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ai-tools\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ai-tools\\lib\\site-packages\\accelerate\\hooks.py:165\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    163\u001B[0m         output \u001B[38;5;241m=\u001B[39m old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 165\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mold_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ai-tools\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:600\u001B[0m, in \u001B[0;36mT5LayerSelfAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001B[0m\n\u001B[0;32m    589\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    590\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    591\u001B[0m     hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    597\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    598\u001B[0m ):\n\u001B[0;32m    599\u001B[0m     normed_hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer_norm(hidden_states)\n\u001B[1;32m--> 600\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSelfAttention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    601\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnormed_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    602\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    603\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    604\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    605\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    606\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    607\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    608\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    609\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m hidden_states \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(attention_output[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m    610\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (hidden_states,) \u001B[38;5;241m+\u001B[39m attention_output[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ai-tools\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ai-tools\\lib\\site-packages\\accelerate\\hooks.py:165\u001B[0m, in \u001B[0;36madd_hook_to_module.<locals>.new_forward\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    163\u001B[0m         output \u001B[38;5;241m=\u001B[39m old_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 165\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mold_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m module\u001B[38;5;241m.\u001B[39m_hf_hook\u001B[38;5;241m.\u001B[39mpost_forward(module, output)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\ai-tools\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:530\u001B[0m, in \u001B[0;36mT5Attention.forward\u001B[1;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001B[0m\n\u001B[0;32m    525\u001B[0m value_states \u001B[38;5;241m=\u001B[39m project(\n\u001B[0;32m    526\u001B[0m     hidden_states, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mv, key_value_states, past_key_value[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    527\u001B[0m )\n\u001B[0;32m    529\u001B[0m \u001B[38;5;66;03m# compute scores\u001B[39;00m\n\u001B[1;32m--> 530\u001B[0m scores \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    531\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquery_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey_states\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    532\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\u001B[39;00m\n\u001B[0;32m    534\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m position_bias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    535\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhas_relative_attention_bias:\n",
      "\u001B[1;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 8.74 GiB (GPU 0; 6.00 GiB total capacity; 466.23 MiB already allocated; 2.99 GiB free; 1.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import mwparserfromhell\n",
    "import pandas as pd\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\", device_map=\"auto\")\n",
    "\n",
    "# Prepare the model for distributed training\n",
    "accelerator = Accelerator()\n",
    "model, tokenizer = accelerator.prepare(model, tokenizer)\n",
    "device = accelerator.device\n",
    "\n",
    "# Load the dataset\n",
    "csv_filename = \"../data/articles.csv\"\n",
    "articles_df = pd.read_csv(csv_filename)\n",
    "articles_dataset = Dataset.from_pandas(articles_df)\n",
    "csv_questions_filename = \"../data/questions.csv\"\n",
    "\n",
    "# Make a query to the model and return the answer\n",
    "def make_query_to_model(query) -> str:\n",
    "    input_ids = tokenizer(query, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "    outputs = model.generate(input_ids, max_length=512, num_beams=4, early_stopping=True, temperature=0.7)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Generate and evaluate questions and answers\n",
    "def generate_and_evaluate_questions_and_answers(row):\n",
    "    text_df = pd.DataFrame(columns=[\"question\", \"answer\"])\n",
    "    parsed_text = mwparserfromhell.parse(row[\"raw_text\"])\n",
    "    for section in parsed_text.get_sections(levels=[2]):\n",
    "        if section.filter_headings()[0].title.strip().lower() in [\"references\", \"external links\"]:\n",
    "            continue\n",
    "        question = make_query_to_model(f\"Ask the large question about following: {row['title']} - {section.strip_code().strip()}\")\n",
    "        answer = make_query_to_model(f\"Answer the question and provide some details. Question: {question}. Context: Article about {row['title']} - {section.strip_code().strip()}\")\n",
    "        if (len(question) < 50) or (len(answer) < 50):\n",
    "            continue\n",
    "        text_df = pd.concat([text_df, pd.DataFrame({\"question\": [question], \"answer\": [answer]})])\n",
    "        print(f\"Question: {question}\\nAnswer: {answer}\\n\\n\")\n",
    "    return text_df\n",
    "\n",
    "# Create a new dataframe to store the generated questions and answers\n",
    "question_answers_df = pd.DataFrame(columns=[\"question\", \"answer\", \"score\"])\n",
    "\n",
    "if not os.path.exists(csv_questions_filename):\n",
    "    # Generate the questions and answers and save them to a CSV file\n",
    "    rows = tqdm(\n",
    "        articles_df.iterrows(),\n",
    "        desc=\"Generating questions and answers\",\n",
    "        total=len(articles_df)\n",
    "    )\n",
    "    for index, row in rows:\n",
    "        created_question_answers = generate_and_evaluate_questions_and_answers(row)\n",
    "        question_answers_df = pd.concat([question_answers_df, created_question_answers])\n",
    "    # Save the generated questions and answers to a CSV file\n",
    "    question_answers_df.to_csv(csv_questions_filename, index=False)\n",
    "else:\n",
    "    # If the CSV file already exists, we just load it\n",
    "    question_answers_df = pd.read_csv(csv_questions_filename)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T16:49:48.862366Z",
     "end_time": "2023-04-20T17:14:41.709508Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
