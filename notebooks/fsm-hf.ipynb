{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AI Agent\n",
    "\n",
    "This notebook shows how to create AI agent, which can answer to questions without LangChain, HayStack or other libraries.\n",
    "This agent will be able to answer to questions using different tools, like Wikipedia, Calculator or other.\n",
    "\n",
    "It uses FSM (using [transitions](https://github.com/pytransitions/transitions) library) to implement agent's behaviour and huggingface's [transformers](https://huggingface.co/transformers/) library to work with LLMs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Installation\n",
    "\n",
    "First of all, we need to install all required libraries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install transitions transformers accelerate"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-19T00:22:49.653833600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialization of model\n",
    "\n",
    "We will use [transformers](https://huggingface.co/transformers/) library to work with T5 model.\n",
    "\n",
    "Nothing special here, just initialization of model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model = \"google/flan-t5-xxl\"\n",
    "\n",
    "pipe = pipeline(\"text2text-generation\", model=model, device_map=\"auto\", model_kwargs={\"load_in_8bit\": True})\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check if model works correctly for our task\n",
    "test_result = pipe(\"Answer only Yes/No. Honestly. Can you answer to this question: 'Is there any meaning of life'. Answer: \")\n",
    "assert test_result[0][\"generated_text\"].strip() == \"No\", \"Model doesn't work correctly\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Agent\n",
    "\n",
    "This class implements agent, which can answer to questions. It has following states:\n",
    "- waiting_for_task\n",
    "    It is initial state. Agent is waiting for request.\n",
    "- choosing_tool\n",
    "    Agent is choosing tool to answer the question.\n",
    "- applying_tool\n",
    "    Agent is applying tool to answer the question.\n",
    "- finished\n",
    "    Agent is answering to the question.\n",
    "\n",
    "This class isn't perfect, but it is good enough to show the idea.\n",
    "It uses Finite State Machine to implement agent's behaviour. It is implemented using [transitions](https://github.com/pytransitions/transitions) library."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Dict, Callable, List, Union\n",
    "import logging\n",
    "from transitions import Machine\n",
    "\n",
    "\n",
    "class Agent(object):\n",
    "    states = [\n",
    "        'waiting_for_task',\n",
    "        'choosing_tool',\n",
    "        'applying_tool',\n",
    "        'finished'\n",
    "    ]\n",
    "\n",
    "    transitions = [\n",
    "        {\n",
    "            \"source\": \"waiting_for_task\",\n",
    "            \"trigger\": \"request\",\n",
    "            \"dest\": \"choosing_tool\",\n",
    "        },\n",
    "        {\n",
    "            \"source\": \"choosing_tool\",\n",
    "            \"trigger\": \"apply_tool\",\n",
    "            \"dest\": \"applying_tool\",\n",
    "        },\n",
    "        {\n",
    "            \"source\": \"choosing_tool\",\n",
    "            \"trigger\": \"answer\",\n",
    "            \"dest\": \"finished\",\n",
    "        },\n",
    "        {\n",
    "            \"source\": \"applying_tool\",\n",
    "            \"trigger\": \"answer\",\n",
    "            \"dest\": \"finished\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    prompt_fn: Callable = None\n",
    "    tools: List[Dict[str, Union[str, Callable[[str], str]]]] = None\n",
    "    machine: Machine = None\n",
    "    final_answer: str = None\n",
    "\n",
    "    def __init__(self, prompt_fn: Callable, tools: List[Dict[str, Union[str, Callable[[str], str]]]]):\n",
    "        self.prompt_fn = prompt_fn\n",
    "        self.tools = tools\n",
    "        self.machine = Machine(\n",
    "            model=self,\n",
    "            states=self.states,\n",
    "            transitions=self.transitions,\n",
    "            initial='waiting_for_task',\n",
    "            send_event=True\n",
    "        )\n",
    "\n",
    "    def on_enter_choosing_tool(self, event):\n",
    "        print(\"Choosing tool\")\n",
    "        tools_list = \"\\n\".join([\"{}: {}\".format(tool[\"name\"], tool[\"description\"]) for tool in self.tools])\n",
    "        prompt = \"\"\"\n",
    "            You have following tools:\n",
    "            {tools}\n",
    "            To choose tool, type name only.\n",
    "            If you don't need any tool to answer the questuin, type 'None'.\n",
    "            Giver Request: {user_query}\n",
    "        \"\"\".format(tools=tools_list, user_query=event.kwargs.get(\"user_query\"))\n",
    "        tool = self.prompt_fn(prompt)\n",
    "        logging.log(logging.INFO, \"Tool: {}\".format(tool))\n",
    "        if tool == \"None\":\n",
    "            self.answer(user_query=event.kwargs.get(\"user_query\"))\n",
    "        else:\n",
    "            self.apply_tool(tool=tool, user_query=event.kwargs.get(\"user_query\"))\n",
    "\n",
    "    def on_enter_applying_tool(self, event):\n",
    "        print(\"Applying tool\")\n",
    "        tool = next(filter(lambda tool: tool[\"name\"] == event.kwargs.get(\"tool\"), self.tools))\n",
    "        tool_result = tool[\"func\"](event.kwargs.get(\"user_query\"))\n",
    "        logging.log(logging.INFO, \"Tool result: {}\".format(tool_result))\n",
    "        self.answer(user_query=event.kwargs.get(\"user_query\"), tool=event.kwargs.get(\"tool\"), tool_result=tool_result)\n",
    "\n",
    "    def on_enter_finished(self, event):\n",
    "        print(\"Answering\")\n",
    "        prompt = \"\"\"\n",
    "            AI: I made investigation about your query:\n",
    "            \"{user_query}\"\n",
    "            AI: I used {tool} and it gave me following result:\n",
    "            \"{tool_result}\"\n",
    "            AI: So, I think the answer is:\n",
    "        \"\"\".format(\n",
    "            user_query=event.kwargs.get(\"user_query\"),\n",
    "            tool=event.kwargs.get(\"tool\"),\n",
    "            tool_result=event.kwargs.get(\"tool_result\")\n",
    "        ).strip()\n",
    "        answer = self.prompt_fn(prompt).strip()\n",
    "        logging.log(logging.INFO, \"Prompt: {prompt} {answer}\".format(prompt=prompt, answer=answer))\n",
    "        self.final_answer = \"{thoughts} {answer}\".format(thoughts=prompt, answer=answer)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Usage\n",
    "\n",
    "Implementation took 92 lines of code. It's bulletproof, no bugs, no errors, no exceptions, no unexpected breaking interface changes. And it works with OSS models.\n",
    "\n",
    "Let's try to use it.\n",
    "\n",
    "First of all, we need to define some tools. We will use two tools:\n",
    "- Wikipedia - TODO - Just a stub for now\n",
    "- Google - TODO - Just a stub for now\n",
    "- Calculator - TODO - Just a stub for now\n",
    "\n",
    "Also we need to create wrapper for our model. It will be used to generate text. If you want to use another model, you need to change only this function.\n",
    "\n",
    "Also i put some logging to see what's going on, sorry for noise."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger('transitions').setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# And some transitions between states. We're lazy, so we'll leave out\n",
    "\n",
    "def make_query(prompt: str) -> str:\n",
    "    return pipe(prompt)[0][\"generated_text\"]\n",
    "\n",
    "\n",
    "tools_dict: List[Dict[str, Union[str, Callable[[str], str]]]] = [\n",
    "    {\n",
    "        \"name\": \"Wikipedia\",\n",
    "        \"description\": \"Useful for general questions\",\n",
    "        \"func\": lambda\n",
    "            query: \"It is a very important person or object. It was created in 1990 by Tim Berners-Lee. And it is very useful.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Google\",\n",
    "        \"description\": \"Useful for actual events\",\n",
    "        \"apply\": lambda query: \"It never happened\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Calculator\",\n",
    "        \"description\": \"Useful for complex calculations\",\n",
    "        \"apply\": lambda query: \"It is 42\"\n",
    "    }\n",
    "]\n",
    "\n",
    "agent = Agent(\n",
    "    prompt_fn=make_query,\n",
    "    tools=tools_dict\n",
    ")\n",
    "\n",
    "print(agent.state)\n",
    "agent.request(user_query=\"What is ms Yanda?\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Future work\n",
    "\n",
    "- Add real tools\n",
    "- Add memory and it's propogation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
